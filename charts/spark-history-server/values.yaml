# Default values for spark-history-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: austinorth/spark-history-server
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  # tag: 1.0.0

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  name: spark-history-server-sa
  # annotations:
  #   # IRSA role attached to service account
  #   eks.amazonaws.com/role-arn: <IRSA ROLE ARN>

# Enter S3 bucket with Spark Event logs location.
# Ensure IRSA roles has permissions to read the files for the given S3 bucket
# sparkHistoryOpts: "-Dspark.history.fs.logDirectory=s3a://<ENTER_S3_BUCKET_NAME>/<PREFIX_FOR_SPARK_EVENT_LOGS>/"
sparkHistoryOpts: ""
sparkConf: |-
  spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.WebIdentityTokenCredentialsProvider
  spark.history.fs.eventLog.rolling.maxFilesToRetain=5
  spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
  spark.eventLog.enabled=true
  spark.history.ui.port=18080

podAnnotations: {}

# Extra custom labels for pods
podLabels: {}

podSecurityContext:
  runAsUser: 1000
  fsGroup: 1000

securityContext:
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000

service:
  externalPort: 80
  internalPort: 18080
  type: ClusterIP

ingress:
  enabled: false
  annotations: {}
  ## Set below values when ingress is enabled
  # ingressClassName:
  # hosts:
  #   - host: <url>
  #     paths:
  #       - <path>

resources:
  limits:
    cpu: 200m
    memory: 2G
  requests:
    cpu: 100m
    memory: 1G

livenessProbe:
  httpGet:
    path: /
    port: 18080
    scheme: HTTP
  timeoutSeconds: 5
  periodSeconds: 30
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: 18080
    scheme: HTTP
  timeoutSeconds: 5
  periodSeconds: 30
  successThreshold: 1
  failureThreshold: 3

nodeSelector: {}

tolerations: []

affinity: {}

# List of extra volume definitions (Kubernetes YAML format) to add to the pod spec.
# Default is empty, meaning no extra volumes are added unless specified here.
# See Kubernetes API reference for syntax (e.g., for PVCs, ConfigMaps, Secrets).
# Example:
# extraVolumes:
#   - name: my-pvc-volume
#     persistentVolumeClaim:
#       claimName: my-existing-pvc
#   - name: shared-scripts
#     configMap:
#       name: my-scripts-cm
extraVolumes: []

# List of extra volume mount definitions (Kubernetes YAML format) for the main container.
# Default is empty. Mounts defined here must correspond by name to volumes
# defined in extraVolumes or built-in volumes.
# Example:
# extraVolumeMounts:
#  - name: my-pvc-volume
#    mountPath: /mnt/data
#    readOnly: true
#  - name: shared-scripts
#    mountPath: /opt/spark/user-scripts
extraVolumeMounts: []
